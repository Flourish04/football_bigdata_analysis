# ðŸš€ HÆ¯á»šNG DáºªN TRIá»‚N KHAI NHANH

## BÆ°á»›c 1: CÃ i Ä‘áº·t Dependencies

### System Requirements
```bash
# Docker & Docker Compose
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo apt-get install docker-compose-plugin

# Python 3.9+
sudo apt-get install python3.9 python3-pip

# Java 11+ (for Spark, Kafka)
sudo apt-get install openjdk-11-jdk

# Git
sudo apt-get install git
```

### Python Packages
```bash
# Táº¡o virtual environment
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate  # Windows

# CÃ i Ä‘áº·t packages
pip install -r requirements.txt
```

## BÆ°á»›c 2: Khá»Ÿi Ä‘á»™ng Infrastructure

### Start all services vá»›i Docker Compose
```bash
# Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services
docker-compose up -d

# Kiá»ƒm tra tráº¡ng thÃ¡i
docker-compose ps

# Xem logs
docker-compose logs -f
```

### CÃ¡c services sáº½ cháº¡y táº¡i:
- **Kafka**: localhost:9092
- **PostgreSQL**: localhost:5432
- **TimescaleDB**: localhost:5433
- **Redis**: localhost:6379
- **Elasticsearch**: localhost:9200
- **Grafana**: http://localhost:3000 (admin/admin)
- **Airflow**: http://localhost:8080 (admin/admin)
- **Jupyter**: http://localhost:8888
- **Prometheus**: http://localhost:9090
- **MinIO**: http://localhost:9001 (minioadmin/minioadmin)
- **Superset**: http://localhost:8088

## BÆ°á»›c 3: Táº¡o Kafka Topics

```bash
# VÃ o container Kafka
docker exec -it kafka bash

# Táº¡o topics
kafka-topics --create --topic live-matches \
  --bootstrap-server localhost:9092 \
  --partitions 10 \
  --replication-factor 1

kafka-topics --create --topic player-events \
  --bootstrap-server localhost:9092 \
  --partitions 20 \
  --replication-factor 1

kafka-topics --create --topic social-media \
  --bootstrap-server localhost:9092 \
  --partitions 50 \
  --replication-factor 1

kafka-topics --create --topic betting-odds \
  --bootstrap-server localhost:9092 \
  --partitions 5 \
  --replication-factor 1

# Liá»‡t kÃª topics
kafka-topics --list --bootstrap-server localhost:9092

# Exit container
exit
```

## BÆ°á»›c 4: Setup Database

```bash
# Káº¿t ná»‘i PostgreSQL
docker exec -it postgres psql -U football_user -d football_analytics

# Táº¡o tables (copy tá»« ARCHITECTURE_DETAILS.md section 4.1)
# Hoáº·c cháº¡y script init
docker exec -i postgres psql -U football_user -d football_analytics < docker/init-db.sql
```

## BÆ°á»›c 5: Láº¥y API Keys

### Football-Data.org API
1. Truy cáº­p: https://www.football-data.org/
2. ÄÄƒng kÃ½ tÃ i khoáº£n free
3. Láº¥y API key tá»« dashboard
4. Cáº­p nháº­t trong `src/kafka_producer_live_matches.py`:
   ```python
   FOOTBALL_API_KEY = 'YOUR_API_KEY_HERE'
   ```

### Twitter API (Optional)
1. Truy cáº­p: https://developer.twitter.com/
2. Táº¡o application
3. Láº¥y API credentials

## BÆ°á»›c 6: Cháº¡y Batch ETL Pipeline

```bash
# Activate virtual environment
source venv/bin/activate

# Cháº¡y batch ETL
cd src
python batch_etl_pipeline.py
```

Output sáº½ Ä‘Æ°á»£c lÆ°u táº¡i:
- Parquet files: `/tmp/football_processed/`
- PostgreSQL: `football_analytics` database

## BÆ°á»›c 7: Cháº¡y Streaming Pipeline

### Terminal 1 - Start Kafka Producer
```bash
cd src
python kafka_producer_live_matches.py
```

### Terminal 2 - Start Spark Streaming Consumer
```bash
cd src
python spark_streaming_consumer.py
```

## BÆ°á»›c 8: Monitoring & Visualization

### Grafana Dashboard
1. Truy cáº­p: http://localhost:3000
2. Login: admin/admin
3. Add datasource â†’ PostgreSQL
   - Host: postgres:5432
   - Database: football_analytics
   - User: football_user
   - Password: football_pass

### Jupyter Notebooks
1. Truy cáº­p: http://localhost:8888
2. Data cÃ³ sáºµn táº¡i: `/home/jovyan/data/`
3. Táº¡o notebook má»›i vÃ  báº¯t Ä‘áº§u phÃ¢n tÃ­ch!

### Apache Superset
1. Truy cáº­p: http://localhost:8088
2. Setup admin user
3. Connect to PostgreSQL
4. Create dashboards

## BÆ°á»›c 9: Airflow DAG (Optional)

```bash
# Copy DAG files
cp dags/*.py airflow/dags/

# Airflow web UI
# http://localhost:8080
# Login: admin/admin

# Trigger DAG manually hoáº·c Ä‘á»ƒ nÃ³ cháº¡y theo schedule
```

## Troubleshooting

### Kafka connection issues
```bash
# Kiá»ƒm tra Kafka logs
docker logs kafka

# Test connection
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic live-matches --from-beginning
```

### PostgreSQL connection issues
```bash
# Check PostgreSQL logs
docker logs postgres

# Test connection
docker exec -it postgres psql -U football_user -d football_analytics -c "SELECT 1;"
```

### Spark memory issues
```bash
# TÄƒng memory trong spark config
spark = SparkSession.builder \
    .config("spark.executor.memory", "8g") \
    .config("spark.driver.memory", "4g") \
    .getOrCreate()
```

### Docker space issues
```bash
# Clean up
docker system prune -a
docker volume prune
```

## Testing

### Test Kafka Producer
```bash
# Terminal 1 - Start consumer Ä‘á»ƒ xem messages
kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic live-matches --from-beginning

# Terminal 2 - Run producer
python src/kafka_producer_live_matches.py
```

### Test Batch ETL
```bash
# Cháº¡y vá»›i sample data
python src/batch_etl_pipeline.py

# Check output
ls -lh /tmp/football_processed/
```

### Test Database
```bash
# Query PostgreSQL
docker exec -it postgres psql -U football_user -d football_analytics \
  -c "SELECT COUNT(*) FROM player_analytics;"
```

## Next Steps

1. âœ… Infrastructure setup hoÃ n táº¥t
2. ðŸ”„ Cháº¡y batch ETL Ä‘á»ƒ load historical data
3. ðŸš€ Start streaming pipeline cho real-time data
4. ðŸ“Š Setup Grafana dashboards
5. ðŸ¤– Train ML models (xem BIGDATA_PROJECT_PLAN.md section 5.3)
6. ðŸŒ Build REST API
7. ðŸ“± Create web dashboard

## Useful Commands

```bash
# Stop all services
docker-compose down

# Stop vÃ  xÃ³a volumes
docker-compose down -v

# Restart má»™t service
docker-compose restart kafka

# View logs cá»§a má»™t service
docker-compose logs -f spark

# Scale a service
docker-compose up -d --scale kafka=3

# Execute command trong container
docker exec -it kafka bash
```

## Resources

- **Documentation**: Xem `BIGDATA_PROJECT_PLAN.md` vÃ  `ARCHITECTURE_DETAILS.md`
- **API Docs**: 
  - Football-Data: https://www.football-data.org/documentation/quickstart
  - Kafka: https://kafka.apache.org/documentation/
  - Spark: https://spark.apache.org/docs/latest/
- **Support**: GitHub Issues

---

**Good luck vá»›i dá»± Ã¡n! âš½ðŸš€**
