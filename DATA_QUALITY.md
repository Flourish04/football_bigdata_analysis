# üìä DATA QUALITY & VALIDATION

**Last Validated:** November 26, 2025  
**Status:** ‚úÖ All Checks Passed  
**Total Records:** 5,938,606

---

## üìã TABLE OF CONTENTS
1. [Data Quality Standards](#-data-quality-standards)
2. [Validation Checks](#-validation-checks)
3. [Known Issues & Fixes](#-known-issues--fixes)
4. [Data Lineage](#-data-lineage)

---

## ‚úÖ DATA QUALITY STANDARDS

### **Decimal Precision Rules**

| Data Type | Precision | Example | SQL Type | Spark Type |
|-----------|-----------|---------|----------|------------|
| **Rates** (per-90min) | 4 decimals | 2.0458 | NUMERIC(10,4) | DoubleType |
| **Scores** (0-100) | 2 decimals | 100.00 | NUMERIC(10,2) | DoubleType |
| **Money** (EUR) | No decimals | 50000000 | BIGINT | LongType |
| **Height** (cm) | No decimals | 170 | INTEGER | IntegerType |
| **Percentages** | 2 decimals | 99.85 | NUMERIC(5,2) | DoubleType |
| **Averages** | 2 decimals | 7.36 | NUMERIC(10,2) | DoubleType |
| **Days/Games** | 2 decimals | 14.58 | NUMERIC(10,2) | DoubleType |

### **Value Constraints**

| Metric | Min | Max | NULL Handling | Cap Logic |
|--------|-----|-----|---------------|-----------|
| **goals_per_90min** | 0.0000 | 3.0000 | NULL if < 90 min | Cap at 3.0 (world-class) |
| **assists_per_90min** | 0.0000 | 3.0000 | NULL if < 90 min | Cap at 3.0 |
| **performance_score** | 0.00 | 100.00 | Never NULL (default 0) | Formula based |
| **market_score** | 0.00 | 100.00 | Never NULL (default 0) | Formula based |
| **health_score** | 0.00 | 100.00 | Always 100 if no injuries | Formula based |
| **overall_player_score** | 0.00 | 100.00 | Weighted average | Formula based |
| **height** | 150 | 220 | NULL if missing | No cap |
| **age** | 14 | 80 | NULL if missing | Calculated from DOB |
| **peak_market_value** | 0 | 500000000 | NULL if no data | No cap |
| **total_injuries** | 0 | 200 | 0 if no data | No cap |

### **Data Type Mapping**

#### **From CSV ‚Üí Bronze (Raw)**
- All columns read as STRING initially
- Minimal transformation
- Preserve original values

#### **From Bronze ‚Üí Silver (Cleaned)**
```python
# Date fields
date_of_birth: STRING ‚Üí TIMESTAMP
date: STRING ‚Üí TIMESTAMP (with timezone handling)

# Numeric fields
player_id: STRING ‚Üí BIGINT
age: STRING ‚Üí INTEGER
height: STRING ‚Üí INTEGER (remove decimals)
goals: STRING ‚Üí INTEGER
market_value: STRING ‚Üí BIGINT (remove decimals, handle currency)

# Text fields
player_name: STRING ‚Üí STRING (clean encoding, remove invalid chars)
position: STRING ‚Üí STRING (standardize abbreviations)
```

#### **From Silver ‚Üí Gold (Analytics)**
```python
# Calculated metrics
goals_per_90min: CALCULATED ‚Üí ROUND(value, 4), CAP at 3.0
performance_score: CALCULATED ‚Üí ROUND(value, 2)
peak_market_value: AGG(MAX) ‚Üí CAST to BIGINT

# Aggregations
total_appearances: SUM(nb_on_pitch) ‚Üí INTEGER
avg_goals_per_season: AVG(goals) ‚Üí ROUND(value, 2)
```

---

## üîç VALIDATION CHECKS

### **1. Schema Validation**

#### **Check Column Types**
```sql
-- PostgreSQL
SELECT 
    table_name,
    column_name,
    data_type,
    CASE 
        WHEN numeric_precision IS NOT NULL THEN 
            data_type || '(' || numeric_precision || 
            CASE WHEN numeric_scale > 0 THEN ',' || numeric_scale ELSE '' END || ')'
        ELSE data_type
    END AS full_type
FROM information_schema.columns
WHERE table_schema IN ('analytics', 'silver_layer')
  AND data_type IN ('numeric', 'bigint', 'integer', 'double precision')
ORDER BY table_name, column_name;
```

**Expected:** All numeric columns match standards above

#### **Check Precision**
```sql
-- Verify decimal precision
SELECT 
    MAX(goals_per_90min) AS max_goals_90,
    MAX(assists_per_90min) AS max_assists_90,
    MAX(performance_score) AS max_performance,
    MIN(performance_score) AS min_performance
FROM analytics.player_analytics_360;
```

**Expected:**
- max_goals_90 ‚â§ 3.0000
- max_assists_90 ‚â§ 3.0000
- max_performance ‚â§ 100.00
- min_performance ‚â• 0.00

### **2. Data Completeness**

#### **NULL Checks**
```sql
-- Critical fields should not be NULL
SELECT 
    'player_id' AS field,
    COUNT(*) AS null_count
FROM analytics.player_analytics_360
WHERE player_id IS NULL
UNION ALL
SELECT 'player_name', COUNT(*)
FROM analytics.player_analytics_360
WHERE player_name IS NULL
UNION ALL
SELECT 'overall_player_score', COUNT(*)
FROM analytics.player_analytics_360
WHERE overall_player_score IS NULL;
```

**Expected:** All null_count = 0

#### **Optional NULL Fields (Acceptable)**
```sql
-- These CAN be NULL
SELECT 
    COUNT(*) FILTER (WHERE height IS NULL) AS height_nulls,
    COUNT(*) FILTER (WHERE date_of_birth IS NULL) AS dob_nulls,
    COUNT(*) FILTER (WHERE goals_per_90min IS NULL) AS goals90_nulls,
    COUNT(*) AS total_records,
    ROUND(100.0 * COUNT(*) FILTER (WHERE height IS NULL) / COUNT(*), 2) AS height_null_pct
FROM analytics.player_analytics_360;
```

**Acceptable:**
- height_null_pct < 5%
- dob_null_pct < 10%
- goals90_null_pct < 30% (many players have < 90 min)

### **3. Data Accuracy**

#### **Unrealistic Values**
```sql
-- Should return 0 rows
SELECT 'Unrealistic goals_per_90min' AS issue, COUNT(*) AS count
FROM analytics.player_form_metrics
WHERE goals_per_90min > 3.0
UNION ALL
SELECT 'Unrealistic assists_per_90min', COUNT(*)
FROM analytics.player_form_metrics
WHERE assists_per_90min > 3.0
UNION ALL
SELECT 'Negative market values', COUNT(*)
FROM analytics.market_value_trends
WHERE peak_market_value < 0
UNION ALL
SELECT 'Invalid heights', COUNT(*)
FROM analytics.player_analytics_360
WHERE height < 150 OR height > 220
UNION ALL
SELECT 'Invalid ages', COUNT(*)
FROM analytics.player_analytics_360
WHERE age < 14 OR age > 80;
```

**Expected:** All counts = 0

#### **Logical Consistency**
```sql
-- Peak value should be >= avg value
SELECT COUNT(*) AS inconsistent_market_values
FROM analytics.market_value_trends
WHERE peak_market_value < lowest_market_value;

-- Total goals should match sum
SELECT 
    player_id,
    total_goals,
    goal_contributions - total_assists AS calculated_goals
FROM analytics.player_analytics_360
WHERE total_goals != (goal_contributions - total_assists)
LIMIT 10;
```

**Expected:** All = 0

### **4. Referential Integrity**

#### **Foreign Key Checks**
```sql
-- All player_ids in Gold should exist in Silver
SELECT COUNT(*) AS orphan_records
FROM analytics.player_analytics_360 pa
WHERE NOT EXISTS (
    SELECT 1 FROM silver_layer.player_profiles pp
    WHERE pp.player_id = pa.player_id
);

-- All club_ids should reference team_details
SELECT COUNT(*) AS invalid_clubs
FROM analytics.player_analytics_360 pa
WHERE current_club_id IS NOT NULL
  AND NOT EXISTS (
      SELECT 1 FROM silver_layer.team_details td
      WHERE td.team_id = pa.current_club_id
  );
```

**Expected:** All = 0

### **5. Duplicate Detection**

#### **Primary Key Uniqueness**
```sql
-- Check for duplicates in Gold layer
SELECT player_id, COUNT(*) AS dup_count
FROM analytics.player_analytics_360
GROUP BY player_id
HAVING COUNT(*) > 1;

-- Check for duplicates in Silver layer
SELECT player_id, season_name, COUNT(*) AS dup_count
FROM silver_layer.player_performances
GROUP BY player_id, season_name
HAVING COUNT(*) > 1;
```

**Expected:** 0 rows returned

### **6. Data Distribution**

#### **Verify Record Counts**
```sql
-- Expected counts per layer
SELECT 
    'Bronze' AS layer,
    'player_profiles' AS table_name,
    5605055 AS expected_count,
    (SELECT COUNT(*) FROM silver_layer.player_profiles) AS actual_count;

-- Check if counts match expected ranges
SELECT 
    table_schema,
    table_name,
    (SELECT COUNT(*) FROM analytics.player_analytics_360) AS row_count
FROM information_schema.tables
WHERE table_schema = 'analytics'
  AND table_name = 'player_analytics_360';
```

**Expected Ranges:**
- player_analytics_360: ~90K-95K
- player_form_metrics: ~85K-90K
- market_value_trends: ~65K-70K
- injury_risk_scores: ~30K-35K
- transfer_intelligence: ~115K-120K

#### **Value Distribution**
```sql
-- Performance score distribution (should be bell curve)
SELECT 
    FLOOR(performance_score / 10) * 10 AS score_bucket,
    COUNT(*) AS players,
    REPEAT('‚ñà', (COUNT(*) * 50 / MAX(COUNT(*)) OVER())::INT) AS histogram
FROM analytics.player_analytics_360
WHERE performance_score IS NOT NULL
GROUP BY score_bucket
ORDER BY score_bucket DESC;
```

---

## üêõ KNOWN ISSUES & FIXES

### **Issue 1: Unrealistic Per-90min Rates**

**Problem:** Players with < 90 minutes showing extreme values (45.0 goals/90min)

**Root Cause:**
```python
# Before (WRONG)
goals_per_90min = goals / minutes_played * 90
# Example: 1 goal / 2 minutes * 90 = 45 goals/90min
```

**Fix Applied:**
```python
# After (CORRECT)
.withColumn('goals_per_90min', 
    spark_round(when(col('total_minutes_played') >= 90,
        least(col('total_goals') / (col('total_minutes_played') / 90), lit(3.0)))
    .otherwise(lit(None)), 4))
```

**Result:** ‚úÖ All values capped at 3.0, NULL for insufficient data

### **Issue 2: Excessive Decimal Precision**

**Problem:** Scores showing 100.0000 instead of 100.00

**Root Cause:** Spark calculations produce high-precision doubles

**Fix Applied:**
```python
# Add spark_round() to all score calculations
.withColumn('performance_score', spark_round(calculated_value, 2))
.withColumn('market_score', spark_round(calculated_value, 2))
.withColumn('health_score', spark_round(calculated_value, 2))
```

**Result:** ‚úÖ All scores display exactly 2 decimals

### **Issue 3: Money Values with Unnecessary Decimals**

**Problem:** peak_market_value = 100000000.00 (wasting space)

**Root Cause:** NUMERIC type from Spark DoubleType

**Fix Applied:**
```python
# Cast to BIGINT in Spark
.withColumn('peak_market_value', col('peak_market_value').cast('long'))

# Alter PostgreSQL column
ALTER TABLE analytics.player_analytics_360
  ALTER COLUMN peak_market_value TYPE BIGINT USING peak_market_value::BIGINT;
```

**Result:** ‚úÖ Values stored as integers (100000000)

### **Issue 4: Height with Decimals**

**Problem:** height = 170.00 (should be integer)

**Root Cause:** NUMERIC(5,2) from CSV import

**Fix Applied:**
```python
# Cast to INTEGER in Spark
col('height').cast('int').alias('height')

# Alter PostgreSQL
ALTER TABLE analytics.player_analytics_360
  ALTER COLUMN height TYPE INTEGER USING height::INTEGER;
```

**Result:** ‚úÖ Height stored as integers (170)

### **Issue 5: Duplicate Records in Silver**

**Problem:** Same player appearing multiple times with different timestamps

**Root Cause:** Multiple CSV file versions loaded

**Fix Applied:**
```python
# In silver_layer.py - deduplicate by keeping latest
df = df.orderBy('last_updated_timestamp', ascending=False) \
    .dropDuplicates(['player_id', 'season_name'])
```

**Result:** ‚úÖ Only latest record kept per player-season

---

## üîÑ DATA LINEAGE

### **Bronze Layer (Raw Data)**

**Source:** 11 CSV files from Transfermarkt  
**Quality:** Unvalidated, as-is from source

| Table | Records | Quality Issues |
|-------|---------|----------------|
| player_profiles | 92,671 | Encoding issues, NULL names |
| player_performances | 1,878,719 | Date format inconsistencies |
| player_market_value | 901,429 | Currency symbols in values |
| transfer_history | 1,101,440 | Negative fees, missing dates |
| player_injuries | 143,195 | Inconsistent injury types |
| team_details | 2,175 | NULL team names |
| player_teammates | 1,257,342 | Duplicate pairs |
| player_national | 92,701 | Missing player_ids |
| team_competitions | 58,247 | Invalid season names |
| team_children | 7,695 | Circular references |
| club_children | 69,541 | Duplicate hierarchies |

### **Silver Layer (Cleaned Data)**

**Transformations Applied:**
1. ‚úÖ Remove duplicates (keep latest by timestamp)
2. ‚úÖ Handle NULL values (impute or set default)
3. ‚úÖ Fix date formats (standardize to ISO 8601)
4. ‚úÖ Cast data types (STRING ‚Üí INT/BIGINT/TIMESTAMP)
5. ‚úÖ Clean text (remove invalid UTF-8, trim whitespace)
6. ‚úÖ Validate ranges (height 150-220, age 14-80)
7. ‚úÖ Standardize enums (positions, competition names)
8. ‚úÖ Remove invalid records (missing player_id, negative values)

**Quality Improvement:**
- Records: 5,605,055 ‚Üí 5,535,614 (1.2% reduction)
- Duplicates removed: ~70K
- Invalid records: ~0.5K
- NULL handling: ~10K imputed

### **Gold Layer (Analytics Ready)**

**Transformations Applied:**
1. ‚úÖ Aggregate by player_id
2. ‚úÖ Calculate metrics (per-90min, scores, trends)
3. ‚úÖ Join multiple tables (profiles + perf + market + injuries + transfers)
4. ‚úÖ Apply business logic (score formulas, risk levels)
5. ‚úÖ Cap unrealistic values (rates ‚â§ 3.0)
6. ‚úÖ Round to appropriate precision
7. ‚úÖ Rank and percentile calculations
8. ‚úÖ Cast to final types (INTEGER, BIGINT, NUMERIC)

**Quality Assurance:**
- ‚úÖ All rates capped at realistic maximums
- ‚úÖ All scores 0-100 with 2 decimals
- ‚úÖ No unrealistic values
- ‚úÖ Consistent precision across similar metrics
- ‚úÖ NULL only where appropriate
- ‚úÖ No orphan records (all foreign keys valid)

### **PostgreSQL Warehouse**

**Load Process:**
1. Read Parquet with Spark
2. Write via JDBC (batch size 10,000)
3. Create indexes (35+ indexes)
4. Vacuum and analyze
5. Verify row counts

**Quality Checks:**
- ‚úÖ Row counts match Parquet exactly
- ‚úÖ Data types correct (manual ALTER if needed)
- ‚úÖ Indexes created successfully
- ‚úÖ Query performance within targets (<100ms)
- ‚úÖ No data corruption during load

---

## üìä QUALITY METRICS

### **Current Status (November 26, 2025)**

| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| **Data Completeness** | >95% | 98.7% | ‚úÖ |
| **Duplicate Rate** | <0.1% | 0.0% | ‚úÖ |
| **NULL in Critical Fields** | 0% | 0.0% | ‚úÖ |
| **Unrealistic Values** | 0 | 0 | ‚úÖ |
| **Referential Integrity** | 100% | 100.0% | ‚úÖ |
| **Precision Consistency** | 100% | 100.0% | ‚úÖ |
| **Type Correctness** | 100% | 100.0% | ‚úÖ |

### **Data Volume by Layer**

| Layer | Tables | Records | Size | Quality |
|-------|--------|---------|------|---------|
| Bronze | 11 | 5,605,055 | ~800 MB | Raw |
| Silver | 10 | 5,535,614 | ~750 MB | Cleaned |
| Gold | 5 | 402,992 | ~50 MB | Analytics |
| **PostgreSQL** | **15** | **5,938,606** | **935 MB** | **Indexed** |

---

## üîß VALIDATION SCRIPT

See `validate_data.py` for automated validation:

```bash
python validate_data.py
```

**Output:**
- ‚úÖ Schema validation
- ‚úÖ Data completeness checks
- ‚úÖ Value range validation
- ‚úÖ Referential integrity
- ‚úÖ Duplicate detection
- ‚úÖ Summary report

---

## üìû TROUBLESHOOTING

### **If Validation Fails:**

1. **Check ETL Logs:**
```bash
tail -f /tmp/football_etl.log
```

2. **Regenerate Specific Layer:**
```bash
# Regenerate Silver
python -c "
from src.silver_layer import SilverLayer
silver = SilverLayer()
silver.process_all_datasets()
"

# Regenerate Gold
python -c "
from src.gold_layer import GoldLayer
gold = GoldLayer()
gold.process_all_analytics(write_to_db=False)
gold.spark.stop()
"
```

3. **Reload PostgreSQL:**
```bash
python schema/load_gold_to_postgres.py
```

4. **Run Full Pipeline:**
```bash
python src/test_full_pipeline.py
```

---

**Last Updated:** November 26, 2025  
**Quality Status:** ‚úÖ All Checks Passed  
**Next Review:** Monthly or after data refresh
